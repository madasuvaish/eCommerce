{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ff4c953-3d14-4204-b5c9-480b6303d401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName         Region SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  7-10-2022\n",
      "1      C0002      Elizabeth Lutz           Asia  2-13-2022\n",
      "2      C0003      Michael Rivera  South America   3-7-2024\n",
      "3      C0004  Kathleen Rodriguez  South America  10-9-2022\n",
      "4      C0005         Laura Weber           Asia  8-15-2022\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets into pandas dataframes\n",
    "customers = pd.read_csv('Customers.csv')  # Load the Customers.csv file\n",
    "products = pd.read_csv('Products.csv')    # Load the Products.csv file\n",
    "transactions = pd.read_csv('Transactions.csv')  # Load the Transactions.csv file\n",
    "\n",
    "# Display the first few rows of each dataframe to check the data\n",
    "print(customers.head())\n",
    "print(products.head())\n",
    "print(transactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5236ac00-80bc-4b0e-8a46-4734717ca298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Customers Data:\n",
      "  CustomerID        CustomerName         Region SignupDate\n",
      "0      C0001    Lawrence Carroll  South America 2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia 2022-02-13\n",
      "2      C0003      Michael Rivera  South America 2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America 2022-10-09\n",
      "4      C0005         Laura Weber           Asia 2022-08-15\n",
      "\n",
      "Cleaned Products Data:\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "\n",
      "Cleaned Transactions Data:\n",
      "  TransactionID CustomerID ProductID     TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067 2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067 2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067 2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067 2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067 2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# 1. Remove duplicates from the datasets\n",
    "customers = customers.drop_duplicates()\n",
    "products = products.drop_duplicates()\n",
    "transactions = transactions.drop_duplicates()\n",
    "\n",
    "# 2. Handle missing values\n",
    "# - Remove rows with missing CustomerID or ProductID in transactions\n",
    "transactions = transactions.dropna(subset=['CustomerID', 'ProductID'])\n",
    "\n",
    "# - Remove rows where CustomerID is missing in customers\n",
    "customers = customers.dropna(subset=['CustomerID'])\n",
    "\n",
    "# 3. Convert date columns to datetime format\n",
    "customers['SignupDate'] = pd.to_datetime(customers['SignupDate'], errors='coerce')\n",
    "transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'], errors='coerce')\n",
    "\n",
    "# 4. Optionally, reset index after cleaning\n",
    "customers = customers.reset_index(drop=True)\n",
    "products = products.reset_index(drop=True)\n",
    "transactions = transactions.reset_index(drop=True)\n",
    "\n",
    "# Display the cleaned data (first 5 rows) to verify\n",
    "print(\"Cleaned Customers Data:\")\n",
    "print(customers.head())\n",
    "print(\"\\nCleaned Products Data:\")\n",
    "print(products.head())\n",
    "print(\"\\nCleaned Transactions Data:\")\n",
    "print(transactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0684be71-2e86-4066-afa4-91d2df2bb33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data (Customer-Transaction-Product Info):\n",
      "  TransactionID CustomerID ProductID     TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067 2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067 2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067 2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067 2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067 2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue  Price_x     CustomerName         Region SignupDate  \\\n",
      "0      300.68   300.68   Andrea Jenkins         Europe 2022-12-03   \n",
      "1      300.68   300.68  Brittany Harvey           Asia 2024-09-04   \n",
      "2      300.68   300.68  Kathryn Stevens         Europe 2024-04-04   \n",
      "3      601.36   300.68  Travis Campbell  South America 2024-04-11   \n",
      "4      902.04   300.68    Timothy Perez         Europe 2022-03-15   \n",
      "\n",
      "                       ProductName     Category  Price_y  \n",
      "0  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "1  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "2  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "3  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "4  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n"
     ]
    }
   ],
   "source": [
    "# Merge customer and transaction data on 'CustomerID' to associate customer details with each transaction\n",
    "customer_transactions = pd.merge(transactions, customers, on='CustomerID', how='left')\n",
    "\n",
    "# Merge the product data with the customer-transaction data on 'ProductID' to get product details\n",
    "customer_transactions = pd.merge(customer_transactions, products, on='ProductID', how='left')\n",
    "\n",
    "# Display the first few rows to check the merged data\n",
    "print(\"Merged Data (Customer-Transaction-Product Info):\")\n",
    "print(customer_transactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d71ca680-679f-40f7-a252-8df4f8a3334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Merged Data with Price column updated:\n",
      "  TransactionID CustomerID ProductID     TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067 2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067 2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067 2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067 2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067 2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue     CustomerName         Region SignupDate  \\\n",
      "0      300.68   Andrea Jenkins         Europe 2022-12-03   \n",
      "1      300.68  Brittany Harvey           Asia 2024-09-04   \n",
      "2      300.68  Kathryn Stevens         Europe 2024-04-04   \n",
      "3      601.36  Travis Campbell  South America 2024-04-11   \n",
      "4      902.04    Timothy Perez         Europe 2022-03-15   \n",
      "\n",
      "                       ProductName     Category   Price  \n",
      "0  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
      "1  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
      "2  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
      "3  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
      "4  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n"
     ]
    }
   ],
   "source": [
    "# Rename Price_y to Price\n",
    "customer_transactions = customer_transactions.rename(columns={'Price_y': 'Price'})\n",
    "\n",
    "# Drop Price_x if it's redundant\n",
    "customer_transactions = customer_transactions.drop(columns=['Price_x'])\n",
    "\n",
    "# Display the cleaned-up data\n",
    "print(\"Cleaned Merged Data with Price column updated:\")\n",
    "print(customer_transactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7eddc288-ae34-4cfc-8b0c-b1aeac1a4b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Cleaned Data for Lookalike Model:\n",
      "  CustomerID ProductID     TransactionDate  Quantity  TotalValue  \\\n",
      "0      C0199      P067 2024-08-25 12:38:23         1      300.68   \n",
      "1      C0146      P067 2024-05-27 22:23:54         1      300.68   \n",
      "2      C0127      P067 2024-04-25 07:38:55         1      300.68   \n",
      "3      C0087      P067 2024-03-26 22:55:37         2      601.36   \n",
      "4      C0070      P067 2024-03-21 15:10:10         3      902.04   \n",
      "\n",
      "                       ProductName     Category   Price  \n",
      "0  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
      "1  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
      "2  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
      "3  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
      "4  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "customer_transactions_cleaned = customer_transactions.drop(columns=['TransactionID', 'CustomerName', 'SignupDate', 'Region'])\n",
    "\n",
    "# Display the cleaned data\n",
    "print(\"Final Cleaned Data for Lookalike Model:\")\n",
    "print(customer_transactions_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f559ae9e-b53d-433a-ba77-473eb1ad6a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID         Region  YearsWithBusiness  TotalSpend  \\\n",
      "0      C0199         Europe           2.150685     1979.28   \n",
      "1      C0146           Asia           0.394521     2570.80   \n",
      "2      C0127         Europe           0.813699     3232.88   \n",
      "3      C0087  South America           0.794521     6604.23   \n",
      "4      C0070         Europe           2.871233     3125.49   \n",
      "\n",
      "   AvgQuantityPurchased  ProductDiversity     Category  \n",
      "0              2.250000                 4   Home Decor  \n",
      "1              2.000000                 4        Books  \n",
      "2              1.833333                 6  Electronics  \n",
      "3              3.142857                 7  Electronics  \n",
      "4              3.000000                 4        Books  \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Ensure that SignupDate is in datetime format\n",
    "customer_transactions['SignupDate'] = pd.to_datetime(customer_transactions['SignupDate'])\n",
    "\n",
    "# Step 1: Calculate YearsWithBusiness\n",
    "current_date = datetime.now()\n",
    "customer_transactions['YearsWithBusiness'] = (current_date - customer_transactions['SignupDate']).dt.days / 365\n",
    "\n",
    "# Step 2: Total Spend - Sum of TotalValue for each customer\n",
    "total_spend = customer_transactions.groupby('CustomerID')['TotalValue'].sum().reset_index()\n",
    "total_spend = total_spend.rename(columns={'TotalValue': 'TotalSpend'})\n",
    "\n",
    "# Step 3: Average Quantity Purchased - Average of Quantity for each customer\n",
    "avg_quantity = customer_transactions.groupby('CustomerID')['Quantity'].mean().reset_index()\n",
    "avg_quantity = avg_quantity.rename(columns={'Quantity': 'AvgQuantityPurchased'})\n",
    "\n",
    "# Step 4: Most Frequent Category - Category that the customer purchases the most\n",
    "category_freq = customer_transactions.groupby(['CustomerID', 'Category'])['Quantity'].sum().reset_index()\n",
    "most_frequent_category = category_freq.loc[category_freq.groupby('CustomerID')['Quantity'].idxmax()]\n",
    "most_frequent_category = most_frequent_category[['CustomerID', 'Category']]\n",
    "\n",
    "# Step 5: Product Diversity - Count of unique products bought by each customer\n",
    "product_diversity = customer_transactions.groupby('CustomerID')['ProductID'].nunique().reset_index()\n",
    "product_diversity = product_diversity.rename(columns={'ProductID': 'ProductDiversity'})\n",
    "\n",
    "# Step 6: Combine all features into a customer profile matrix\n",
    "customer_profile = pd.merge(customer_transactions[['CustomerID', 'Region', 'YearsWithBusiness']], total_spend, on='CustomerID', how='left')\n",
    "customer_profile = pd.merge(customer_profile, avg_quantity, on='CustomerID', how='left')\n",
    "customer_profile = pd.merge(customer_profile, product_diversity, on='CustomerID', how='left')\n",
    "\n",
    "# Add Most Frequent Category\n",
    "customer_profile = pd.merge(customer_profile, most_frequent_category, on='CustomerID', how='left')\n",
    "\n",
    "# Fill missing values with 0 (if no transactions)\n",
    "customer_profile = customer_profile.fillna(0)\n",
    "\n",
    "# Display the customer profile matrix\n",
    "print(customer_profile.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00b8c3be-0fa2-4b3c-b9e0-4585668854df",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MostFrequentCategory'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MostFrequentCategory'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Step 2: Convert categorical features to numeric\u001b[39;00m\n\u001b[0;32m     13\u001b[0m customer_profile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m customer_profile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcodes\n\u001b[1;32m---> 14\u001b[0m customer_profile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMostFrequentCategory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcustomer_profile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMostFrequentCategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcodes\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Step 3: Prepare the feature matrix for similarity calculation\u001b[39;00m\n\u001b[0;32m     17\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYearsWithBusiness\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotalSpend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvgQuantityPurchased\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProductDiversity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMostFrequentCategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MostFrequentCategory'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming your customer profile data is already loaded in the 'customer_profile' DataFrame\n",
    "\n",
    "# Step 1: Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['YearsWithBusiness', 'TotalSpend', 'AvgQuantityPurchased', 'ProductDiversity']\n",
    "customer_profile[numerical_features] = scaler.fit_transform(customer_profile[numerical_features])\n",
    "\n",
    "# Step 2: Convert categorical features to numeric\n",
    "customer_profile['Region'] = customer_profile['Region'].astype('category').cat.codes\n",
    "customer_profile['MostFrequentCategory'] = customer_profile['MostFrequentCategory'].astype('category').cat.codes\n",
    "\n",
    "# Step 3: Prepare the feature matrix for similarity calculation\n",
    "features = ['Region', 'YearsWithBusiness', 'TotalSpend', 'AvgQuantityPurchased', 'ProductDiversity', 'MostFrequentCategory']\n",
    "X = customer_profile[features]\n",
    "\n",
    "# Step 4: Calculate cosine similarity between customers\n",
    "cosine_sim = cosine_similarity(X)\n",
    "\n",
    "# Step 5: Create a dictionary to store the top 3 lookalikes for each customer\n",
    "lookalikes = {}\n",
    "\n",
    "# For each customer, find the top 3 most similar customers\n",
    "for idx, row in customer_profile.iterrows():\n",
    "    customer_id = row['CustomerID']\n",
    "    \n",
    "    # Get similarity scores for the current customer\n",
    "    similarity_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort by similarity score in descending order, excluding the customer itself\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top 3 lookalikes (excluding the customer itself)\n",
    "    top_lookalikes = [(customer_profile.iloc[i[0]]['CustomerID'], i[1]) for i in similarity_scores[1:4]]\n",
    "    \n",
    "    # Store the results in the dictionary\n",
    "    lookalikes[customer_id] = top_lookalikes\n",
    "\n",
    "# Step 6: Format the results into a DataFrame for CSV export\n",
    "lookalike_df = pd.DataFrame(\n",
    "    [(cust_id, \n",
    "      lookalikes[cust_id][0][0], lookalikes[cust_id][0][1], \n",
    "      lookalikes[cust_id][1][0], lookalikes[cust_id][1][1], \n",
    "      lookalikes[cust_id][2][0], lookalikes[cust_id][2][1]) \n",
    "     for cust_id in lookalikes], \n",
    "    columns=['CustomerID', 'Lookalike1', 'Similarity1', 'Lookalike2', 'Similarity2', 'Lookalike3', 'Similarity3']\n",
    ")\n",
    "\n",
    "# Step 7: Export the results to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
    "\n",
    "# Display the first 20 customers' top lookalikes\n",
    "print(lookalike_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9746fdce-e1d4-4fe6-8f92-ae0e2a2f3fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID Lookalike1  Similarity1 Lookalike2  Similarity2 Lookalike3  \\\n",
      "0       C0199      C0060     0.967580      C0025     0.943137      C0025   \n",
      "1       C0146      C0056     0.973158      C0056     0.973158      C0056   \n",
      "2       C0127      C0172     0.986666      C0172     0.986666      C0172   \n",
      "3       C0087      C0046     0.928190      C0046     0.928190      C0046   \n",
      "4       C0070      C0074     0.927349      C0074     0.927349      C0074   \n",
      "5       C0188      C0102     0.989530      C0102     0.989530      C0102   \n",
      "6       C0195      C0012     0.987574      C0012     0.987574      C0012   \n",
      "7       C0008      C0051     0.908467      C0051     0.908467      C0051   \n",
      "8       C0157      C0076     0.968601      C0076     0.968601      C0076   \n",
      "9       C0130      C0042     0.980591      C0042     0.980591      C0042   \n",
      "10      C0051      C0059     0.965693      C0059     0.965693      C0059   \n",
      "11      C0075      C0156     0.858256      C0156     0.858256      C0156   \n",
      "12      C0155      C0004     0.945396      C0004     0.945396      C0004   \n",
      "13      C0092      C0115     0.946716      C0115     0.946716      C0115   \n",
      "14      C0088      C0128     0.946484      C0128     0.946484      C0097   \n",
      "15      C0109      C0099     0.868824      C0099     0.868824      C0099   \n",
      "16      C0041      C0087     0.862533      C0087     0.862533      C0087   \n",
      "17      C0101      C0141     0.874504      C0141     0.874504      C0141   \n",
      "18      C0154      C0127     0.948401      C0127     0.948401      C0127   \n",
      "19      C0200      C0136     0.859745      C0136     0.859745      C0136   \n",
      "\n",
      "    Similarity3  \n",
      "0      0.943137  \n",
      "1      0.973158  \n",
      "2      0.986666  \n",
      "3      0.928190  \n",
      "4      0.927349  \n",
      "5      0.989530  \n",
      "6      0.987574  \n",
      "7      0.908467  \n",
      "8      0.968601  \n",
      "9      0.980591  \n",
      "10     0.965693  \n",
      "11     0.858256  \n",
      "12     0.945396  \n",
      "13     0.946716  \n",
      "14     0.940910  \n",
      "15     0.868824  \n",
      "16     0.862533  \n",
      "17     0.874504  \n",
      "18     0.948401  \n",
      "19     0.859745  \n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create a dictionary to store the top 3 lookalikes for each customer\n",
    "lookalikes = {}\n",
    "\n",
    "# Step 7: Calculate cosine similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate cosine similarity between all customers\n",
    "cosine_sim = cosine_similarity(customer_profile[features])  # Use only the numeric features\n",
    "\n",
    "# Step 8: Iterate over each customer and find their top 3 lookalikes\n",
    "for idx, row in customer_profile.iterrows():\n",
    "    customer_id = row['CustomerID']\n",
    "    \n",
    "    # Get similarity scores for the current customer\n",
    "    similarity_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort by similarity score in descending order (exclude self-similarity)\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Exclude the self-similarity (the first customer will have a similarity of 1)\n",
    "    top_lookalikes = []\n",
    "    count = 0\n",
    "    for i in similarity_scores:\n",
    "        if count == 3:\n",
    "            break\n",
    "        if customer_profile.iloc[i[0]]['CustomerID'] != customer_id:\n",
    "            top_lookalikes.append((customer_profile.iloc[i[0]]['CustomerID'], i[1]))\n",
    "            count += 1\n",
    "\n",
    "    # Store the results in the dictionary\n",
    "    lookalikes[customer_id] = top_lookalikes\n",
    "\n",
    "# Step 9: Format the results into a DataFrame for CSV export\n",
    "lookalike_df = pd.DataFrame(\n",
    "    [(cust_id, \n",
    "      lookalikes[cust_id][0][0], lookalikes[cust_id][0][1], \n",
    "      lookalikes[cust_id][1][0], lookalikes[cust_id][1][1], \n",
    "      lookalikes[cust_id][2][0], lookalikes[cust_id][2][1]) \n",
    "     for cust_id in lookalikes], \n",
    "    columns=['CustomerID', 'Lookalike1', 'Similarity1', 'Lookalike2', 'Similarity2', 'Lookalike3', 'Similarity3']\n",
    ")\n",
    "\n",
    "# Step 10: Export the results to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
    "\n",
    "# Display the first 20 customers' top lookalikes\n",
    "print(lookalike_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95003bb6-7271-4c12-8c7f-33af47ebeca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID                                         Lookalikes\n",
      "0       C0199  [(C0060, 0.9675802645771927), (C0025, 0.943137...\n",
      "1       C0146  [(C0056, 0.9731582692752938), (C0056, 0.973158...\n",
      "2       C0127  [(C0172, 0.9866659499226321), (C0172, 0.986665...\n",
      "3       C0087  [(C0046, 0.9281896971144319), (C0046, 0.928189...\n",
      "4       C0070  [(C0074, 0.9273494996680743), (C0074, 0.927349...\n",
      "5       C0188  [(C0102, 0.9895303482968874), (C0102, 0.989530...\n",
      "6       C0195  [(C0012, 0.9875740124980804), (C0012, 0.987574...\n",
      "7       C0008  [(C0051, 0.9084667235002782), (C0051, 0.908466...\n",
      "8       C0157  [(C0076, 0.9686007823213314), (C0076, 0.968600...\n",
      "9       C0130  [(C0042, 0.9805906575928739), (C0042, 0.980590...\n",
      "10      C0051  [(C0059, 0.9656934197496126), (C0059, 0.965693...\n",
      "11      C0075  [(C0156, 0.858256029555297), (C0156, 0.8582560...\n",
      "12      C0155  [(C0004, 0.9453961792622294), (C0004, 0.945396...\n",
      "13      C0092  [(C0115, 0.9467158660692199), (C0115, 0.946715...\n",
      "14      C0088  [(C0128, 0.9464838863203805), (C0128, 0.946483...\n",
      "15      C0109  [(C0099, 0.8688243358191481), (C0099, 0.868824...\n",
      "16      C0041  [(C0087, 0.8625325096686716), (C0087, 0.862532...\n",
      "17      C0101  [(C0141, 0.8745044570131963), (C0141, 0.874504...\n",
      "18      C0154  [(C0127, 0.9484010535841767), (C0127, 0.948401...\n",
      "19      C0200  [(C0136, 0.8597452199869263), (C0136, 0.859745...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming you have already created the `customer_profile` DataFrame and the similarity matrix\n",
    "\n",
    "# Calculate cosine similarity between all customers based on the numeric features\n",
    "cosine_sim = cosine_similarity(customer_profile[features])\n",
    "\n",
    "# Dictionary to store the top 3 lookalikes for each customer\n",
    "lookalikes = {}\n",
    "\n",
    "# Loop through the first 20 customers to identify top 3 lookalikes\n",
    "for idx, row in customer_profile.head(20).iterrows():\n",
    "    customer_id = row['CustomerID']\n",
    "    \n",
    "    # Get similarity scores for the current customer\n",
    "    similarity_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort by similarity score in descending order (excluding self-similarity)\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Collect the top 3 lookalikes\n",
    "    top_lookalikes = []\n",
    "    count = 0\n",
    "    for i in similarity_scores:\n",
    "        if count == 3:\n",
    "            break\n",
    "        if customer_profile.iloc[i[0]]['CustomerID'] != customer_id:\n",
    "            top_lookalikes.append((customer_profile.iloc[i[0]]['CustomerID'], i[1]))\n",
    "            count += 1\n",
    "    \n",
    "    # Store the result in the dictionary\n",
    "    lookalikes[customer_id] = top_lookalikes\n",
    "\n",
    "# Create a DataFrame for the output\n",
    "lookalike_df = pd.DataFrame(\n",
    "    [(cust_id, lookalikes[cust_id]) for cust_id in lookalikes], \n",
    "    columns=['CustomerID', 'Lookalikes']\n",
    ")\n",
    "\n",
    "# Save the result to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
    "\n",
    "# Display the result (top 3 lookalikes for first 20 customers)\n",
    "print(lookalike_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d6ba133-f76d-4636-8ae4-07c6a47bc1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID                                         Lookalikes\n",
      "0       C0199  [(C0060, 0.9675802645771927), (C0025, 0.943137...\n",
      "1       C0146  [(C0056, 0.9731582692752938), (C0056, 0.973158...\n",
      "2       C0127  [(C0172, 0.9866659499226321), (C0172, 0.986665...\n",
      "3       C0087  [(C0046, 0.9281896971144319), (C0046, 0.928189...\n",
      "4       C0070  [(C0074, 0.9273494996680743), (C0074, 0.927349...\n",
      "5       C0188  [(C0102, 0.9895303482968874), (C0102, 0.989530...\n",
      "6       C0195  [(C0012, 0.9875740124980804), (C0012, 0.987574...\n",
      "7       C0008  [(C0051, 0.9084667235002782), (C0051, 0.908466...\n",
      "8       C0157  [(C0076, 0.9686007823213314), (C0076, 0.968600...\n",
      "9       C0130  [(C0042, 0.9805906575928739), (C0042, 0.980590...\n",
      "10      C0051  [(C0059, 0.9656934197496126), (C0059, 0.965693...\n",
      "11      C0075  [(C0156, 0.858256029555297), (C0156, 0.8582560...\n",
      "12      C0155  [(C0004, 0.9453961792622294), (C0004, 0.945396...\n",
      "13      C0092  [(C0115, 0.9467158660692199), (C0115, 0.946715...\n",
      "14      C0088  [(C0128, 0.9464838863203805), (C0128, 0.946483...\n",
      "15      C0109  [(C0099, 0.8688243358191481), (C0099, 0.868824...\n",
      "16      C0041  [(C0087, 0.8625325096686716), (C0087, 0.862532...\n",
      "17      C0101  [(C0141, 0.8745044570131963), (C0141, 0.874504...\n",
      "18      C0154  [(C0127, 0.9484010535841767), (C0127, 0.948401...\n",
      "19      C0200  [(C0136, 0.8597452199869263), (C0136, 0.859745...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming customer_profile DataFrame already has the processed customer features\n",
    "\n",
    "# Step 1: Calculate cosine similarity matrix between customers\n",
    "features = ['Region', 'YearsWithBusiness', 'TotalSpend', 'AvgQuantityPurchased', 'ProductDiversity', 'MostFrequentCategory']\n",
    "cosine_sim = cosine_similarity(customer_profile[features])\n",
    "\n",
    "# Step 2: Prepare a dictionary to store the lookalikes for the first 20 customers\n",
    "lookalikes = {}\n",
    "\n",
    "# Step 3: Loop through the first 20 customers to get the top 3 lookalikes\n",
    "for idx, row in customer_profile.head(20).iterrows():\n",
    "    customer_id = row['CustomerID']\n",
    "    \n",
    "    # Get similarity scores for the current customer\n",
    "    similarity_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort by similarity score in descending order (ignoring self-similarity)\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Collect the top 3 lookalikes with their similarity scores\n",
    "    top_lookalikes = []\n",
    "    count = 0\n",
    "    for i in similarity_scores:\n",
    "        if count == 3:\n",
    "            break\n",
    "        if customer_profile.iloc[i[0]]['CustomerID'] != customer_id:\n",
    "            top_lookalikes.append((customer_profile.iloc[i[0]]['CustomerID'], i[1]))\n",
    "            count += 1\n",
    "    \n",
    "    # Store the result in the dictionary\n",
    "    lookalikes[customer_id] = top_lookalikes\n",
    "\n",
    "# Step 4: Convert the lookalikes dictionary to a DataFrame\n",
    "lookalike_df = pd.DataFrame(\n",
    "    [(cust_id, lookalikes[cust_id]) for cust_id in lookalikes], \n",
    "    columns=['CustomerID', 'Lookalikes']\n",
    ")\n",
    "\n",
    "# Step 5: Save the result to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
    "\n",
    "# Display the first few entries (top 3 lookalikes for the first 20 customers)\n",
    "print(lookalike_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e853d021-4850-4498-9f2b-e6be861404d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID                                         Lookalikes\n",
      "0       C0199  [(C0060, 0.9675802645771927), (C0025, 0.943137...\n",
      "1       C0146  [(C0056, 0.9731582692752938), (C0056, 0.973158...\n",
      "2       C0127  [(C0172, 0.9866659499226321), (C0172, 0.986665...\n",
      "3       C0087  [(C0046, 0.9281896971144319), (C0046, 0.928189...\n",
      "4       C0070  [(C0074, 0.9273494996680743), (C0074, 0.927349...\n",
      "5       C0188  [(C0102, 0.9895303482968874), (C0102, 0.989530...\n",
      "6       C0195  [(C0012, 0.9875740124980804), (C0012, 0.987574...\n",
      "7       C0008  [(C0051, 0.9084667235002782), (C0051, 0.908466...\n",
      "8       C0157  [(C0076, 0.9686007823213314), (C0076, 0.968600...\n",
      "9       C0130  [(C0042, 0.9805906575928739), (C0042, 0.980590...\n",
      "10      C0051  [(C0059, 0.9656934197496126), (C0059, 0.965693...\n",
      "11      C0075  [(C0156, 0.858256029555297), (C0156, 0.8582560...\n",
      "12      C0155  [(C0004, 0.9453961792622294), (C0004, 0.945396...\n",
      "13      C0092  [(C0115, 0.9467158660692199), (C0115, 0.946715...\n",
      "14      C0088  [(C0128, 0.9464838863203805), (C0128, 0.946483...\n",
      "15      C0109  [(C0099, 0.8688243358191481), (C0099, 0.868824...\n",
      "16      C0041  [(C0087, 0.8625325096686716), (C0087, 0.862532...\n",
      "17      C0101  [(C0141, 0.8745044570131963), (C0141, 0.874504...\n",
      "18      C0154  [(C0127, 0.9484010535841767), (C0127, 0.948401...\n",
      "19      C0200  [(C0136, 0.8597452199869263), (C0136, 0.859745...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set pandas display options to show full precision\n",
    "pd.set_option('display.float_format', '{:.16f}'.format)\n",
    "\n",
    "# After setting this, the similarity scores will display fully without truncation.\n",
    "print(lookalike_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "252ecda3-0976-47d1-9886-2db7226373a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  \\\n",
      "0       C0199   \n",
      "1       C0146   \n",
      "2       C0127   \n",
      "3       C0087   \n",
      "4       C0070   \n",
      "5       C0188   \n",
      "6       C0195   \n",
      "7       C0008   \n",
      "8       C0157   \n",
      "9       C0130   \n",
      "10      C0051   \n",
      "11      C0075   \n",
      "12      C0155   \n",
      "13      C0092   \n",
      "14      C0088   \n",
      "15      C0109   \n",
      "16      C0041   \n",
      "17      C0101   \n",
      "18      C0154   \n",
      "19      C0200   \n",
      "\n",
      "                                                                                 Lookalikes  \n",
      "0     [(C0060, 0.9675802645771927), (C0025, 0.943137156872213), (C0025, 0.943137156872213)]  \n",
      "1   [(C0056, 0.9731582692752938), (C0056, 0.9731582692752938), (C0056, 0.9731582692752938)]  \n",
      "2   [(C0172, 0.9866659499226321), (C0172, 0.9866659499226321), (C0172, 0.9866659499226321)]  \n",
      "3   [(C0046, 0.9281896971144319), (C0046, 0.9281896971144319), (C0046, 0.9281896971144319)]  \n",
      "4   [(C0074, 0.9273494996680743), (C0074, 0.9273494996680743), (C0074, 0.9273494996680743)]  \n",
      "5   [(C0102, 0.9895303482968874), (C0102, 0.9895303482968874), (C0102, 0.9895303482968874)]  \n",
      "6   [(C0012, 0.9875740124980804), (C0012, 0.9875740124980804), (C0012, 0.9875740124980804)]  \n",
      "7   [(C0051, 0.9084667235002782), (C0051, 0.9084667235002782), (C0051, 0.9084667235002782)]  \n",
      "8   [(C0076, 0.9686007823213314), (C0076, 0.9686007823213314), (C0076, 0.9686007823213314)]  \n",
      "9   [(C0042, 0.9805906575928739), (C0042, 0.9805906575928739), (C0042, 0.9805906575928739)]  \n",
      "10  [(C0059, 0.9656934197496126), (C0059, 0.9656934197496126), (C0059, 0.9656934197496126)]  \n",
      "11     [(C0156, 0.858256029555297), (C0156, 0.858256029555297), (C0156, 0.858256029555297)]  \n",
      "12  [(C0004, 0.9453961792622294), (C0004, 0.9453961792622294), (C0004, 0.9453961792622294)]  \n",
      "13  [(C0115, 0.9467158660692199), (C0115, 0.9467158660692199), (C0115, 0.9467158660692199)]  \n",
      "14  [(C0128, 0.9464838863203805), (C0128, 0.9464838863203805), (C0097, 0.9409102903968701)]  \n",
      "15  [(C0099, 0.8688243358191481), (C0099, 0.8688243358191481), (C0099, 0.8688243358191481)]  \n",
      "16  [(C0087, 0.8625325096686716), (C0087, 0.8625325096686716), (C0087, 0.8625325096686716)]  \n",
      "17  [(C0141, 0.8745044570131963), (C0141, 0.8745044570131963), (C0141, 0.8745044570131963)]  \n",
      "18  [(C0127, 0.9484010535841767), (C0127, 0.9484010535841767), (C0127, 0.9484010535841767)]  \n",
      "19  [(C0136, 0.8597452199869263), (C0136, 0.8597452199869263), (C0136, 0.8597452199869263)]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)  # To ensure full content in each column is shown\n",
    "\n",
    "\n",
    "print(lookalike_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dbc9dea-e8aa-4522-bcbe-1c3df8fe91ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  \\\n",
      "0       C0199   \n",
      "1       C0146   \n",
      "2       C0127   \n",
      "3       C0087   \n",
      "4       C0070   \n",
      "5       C0188   \n",
      "6       C0195   \n",
      "7       C0008   \n",
      "8       C0157   \n",
      "9       C0130   \n",
      "10      C0051   \n",
      "11      C0075   \n",
      "12      C0155   \n",
      "13      C0092   \n",
      "14      C0088   \n",
      "15      C0109   \n",
      "16      C0041   \n",
      "17      C0101   \n",
      "18      C0154   \n",
      "19      C0200   \n",
      "\n",
      "                                                                                       Lookalikes  \n",
      "0   [('C0060', np.float64(0.9676)), ('C0025', np.float64(0.9431)), ('C0025', np.float64(0.9431))]  \n",
      "1   [('C0056', np.float64(0.9732)), ('C0056', np.float64(0.9732)), ('C0056', np.float64(0.9732))]  \n",
      "2   [('C0172', np.float64(0.9867)), ('C0172', np.float64(0.9867)), ('C0172', np.float64(0.9867))]  \n",
      "3   [('C0046', np.float64(0.9282)), ('C0046', np.float64(0.9282)), ('C0046', np.float64(0.9282))]  \n",
      "4   [('C0074', np.float64(0.9273)), ('C0074', np.float64(0.9273)), ('C0074', np.float64(0.9273))]  \n",
      "5   [('C0102', np.float64(0.9895)), ('C0102', np.float64(0.9895)), ('C0102', np.float64(0.9895))]  \n",
      "6   [('C0012', np.float64(0.9876)), ('C0012', np.float64(0.9876)), ('C0012', np.float64(0.9876))]  \n",
      "7   [('C0051', np.float64(0.9085)), ('C0051', np.float64(0.9085)), ('C0051', np.float64(0.9085))]  \n",
      "8   [('C0076', np.float64(0.9686)), ('C0076', np.float64(0.9686)), ('C0076', np.float64(0.9686))]  \n",
      "9   [('C0042', np.float64(0.9806)), ('C0042', np.float64(0.9806)), ('C0042', np.float64(0.9806))]  \n",
      "10  [('C0059', np.float64(0.9657)), ('C0059', np.float64(0.9657)), ('C0059', np.float64(0.9657))]  \n",
      "11  [('C0156', np.float64(0.8583)), ('C0156', np.float64(0.8583)), ('C0156', np.float64(0.8583))]  \n",
      "12  [('C0004', np.float64(0.9454)), ('C0004', np.float64(0.9454)), ('C0004', np.float64(0.9454))]  \n",
      "13  [('C0115', np.float64(0.9467)), ('C0115', np.float64(0.9467)), ('C0115', np.float64(0.9467))]  \n",
      "14  [('C0128', np.float64(0.9465)), ('C0128', np.float64(0.9465)), ('C0097', np.float64(0.9409))]  \n",
      "15  [('C0099', np.float64(0.8688)), ('C0099', np.float64(0.8688)), ('C0099', np.float64(0.8688))]  \n",
      "16  [('C0087', np.float64(0.8625)), ('C0087', np.float64(0.8625)), ('C0087', np.float64(0.8625))]  \n",
      "17  [('C0141', np.float64(0.8745)), ('C0141', np.float64(0.8745)), ('C0141', np.float64(0.8745))]  \n",
      "18  [('C0127', np.float64(0.9484)), ('C0127', np.float64(0.9484)), ('C0127', np.float64(0.9484))]  \n",
      "19  [('C0136', np.float64(0.8597)), ('C0136', np.float64(0.8597)), ('C0136', np.float64(0.8597))]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming customer_profile DataFrame already has the processed customer features\n",
    "\n",
    "# Step 1: Calculate cosine similarity matrix between customers\n",
    "features = ['Region', 'YearsWithBusiness', 'TotalSpend', 'AvgQuantityPurchased', 'ProductDiversity', 'MostFrequentCategory']\n",
    "cosine_sim = cosine_similarity(customer_profile[features])\n",
    "\n",
    "# Step 2: Prepare a dictionary to store the lookalikes for the first 20 customers\n",
    "lookalikes = {}\n",
    "\n",
    "# Step 3: Loop through the first 20 customers to get the top 3 lookalikes\n",
    "for idx, row in customer_profile.head(20).iterrows():\n",
    "    customer_id = row['CustomerID']\n",
    "    \n",
    "    # Get similarity scores for the current customer\n",
    "    similarity_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort by similarity score in descending order (ignoring self-similarity)\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Collect the top 3 lookalikes with their similarity scores\n",
    "    top_lookalikes = []\n",
    "    count = 0\n",
    "    for i in similarity_scores:\n",
    "        if count == 3:\n",
    "            break\n",
    "        if customer_profile.iloc[i[0]]['CustomerID'] != customer_id:\n",
    "            # Convert the similarity score to a float and round it\n",
    "            score = round(i[1], 4)  # Rounding to 4 decimal places\n",
    "            top_lookalikes.append((customer_profile.iloc[i[0]]['CustomerID'], score))\n",
    "            count += 1\n",
    "    \n",
    "    # Store the result in the dictionary\n",
    "    lookalikes[customer_id] = top_lookalikes\n",
    "\n",
    "# Step 4: Convert the lookalikes dictionary to a DataFrame with a Map structure\n",
    "lookalike_df = pd.DataFrame(\n",
    "    [(cust_id, str(lookalikes[cust_id])) for cust_id in lookalikes], \n",
    "    columns=['CustomerID', 'Lookalikes']\n",
    ")\n",
    "\n",
    "# Step 5: Save the result to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
    "\n",
    "# Display the first few entries (top 3 lookalikes for the first 20 customers)\n",
    "print(lookalike_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1477736e-9e11-47c7-9cc9-3a268dc01261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID                                                 Lookalikes\n",
      "0       C0199  [('C0060', 0.9676), ('C0025', 0.9431), ('C0025', 0.9431)]\n",
      "1       C0146  [('C0056', 0.9732), ('C0056', 0.9732), ('C0056', 0.9732)]\n",
      "2       C0127  [('C0172', 0.9867), ('C0172', 0.9867), ('C0172', 0.9867)]\n",
      "3       C0087  [('C0046', 0.9282), ('C0046', 0.9282), ('C0046', 0.9282)]\n",
      "4       C0070  [('C0074', 0.9273), ('C0074', 0.9273), ('C0074', 0.9273)]\n",
      "5       C0188  [('C0102', 0.9895), ('C0102', 0.9895), ('C0102', 0.9895)]\n",
      "6       C0195  [('C0012', 0.9876), ('C0012', 0.9876), ('C0012', 0.9876)]\n",
      "7       C0008  [('C0051', 0.9085), ('C0051', 0.9085), ('C0051', 0.9085)]\n",
      "8       C0157  [('C0076', 0.9686), ('C0076', 0.9686), ('C0076', 0.9686)]\n",
      "9       C0130  [('C0042', 0.9806), ('C0042', 0.9806), ('C0042', 0.9806)]\n",
      "10      C0051  [('C0059', 0.9657), ('C0059', 0.9657), ('C0059', 0.9657)]\n",
      "11      C0075  [('C0156', 0.8583), ('C0156', 0.8583), ('C0156', 0.8583)]\n",
      "12      C0155  [('C0004', 0.9454), ('C0004', 0.9454), ('C0004', 0.9454)]\n",
      "13      C0092  [('C0115', 0.9467), ('C0115', 0.9467), ('C0115', 0.9467)]\n",
      "14      C0088  [('C0128', 0.9465), ('C0128', 0.9465), ('C0097', 0.9409)]\n",
      "15      C0109  [('C0099', 0.8688), ('C0099', 0.8688), ('C0099', 0.8688)]\n",
      "16      C0041  [('C0087', 0.8625), ('C0087', 0.8625), ('C0087', 0.8625)]\n",
      "17      C0101  [('C0141', 0.8745), ('C0141', 0.8745), ('C0141', 0.8745)]\n",
      "18      C0154  [('C0127', 0.9484), ('C0127', 0.9484), ('C0127', 0.9484)]\n",
      "19      C0200  [('C0136', 0.8597), ('C0136', 0.8597), ('C0136', 0.8597)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming customer_profile DataFrame already has the processed customer features\n",
    "\n",
    "# Step 1: Calculate cosine similarity matrix between customers\n",
    "features = ['Region', 'YearsWithBusiness', 'TotalSpend', 'AvgQuantityPurchased', 'ProductDiversity', 'MostFrequentCategory']\n",
    "cosine_sim = cosine_similarity(customer_profile[features])\n",
    "\n",
    "# Step 2: Prepare a dictionary to store the lookalikes for the first 20 customers\n",
    "lookalikes = {}\n",
    "\n",
    "# Step 3: Loop through the first 20 customers to get the top 3 lookalikes\n",
    "for idx, row in customer_profile.head(20).iterrows():\n",
    "    customer_id = row['CustomerID']\n",
    "    \n",
    "    # Get similarity scores for the current customer\n",
    "    similarity_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort by similarity score in descending order (ignoring self-similarity)\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Collect the top 3 lookalikes with their similarity scores\n",
    "    top_lookalikes = []\n",
    "    count = 0\n",
    "    for i in similarity_scores:\n",
    "        if count == 3:\n",
    "            break\n",
    "        if customer_profile.iloc[i[0]]['CustomerID'] != customer_id:\n",
    "            # Convert np.float64 to regular float and round it\n",
    "            score = round(float(i[1]), 4)  # Convert to float and round to 4 decimal places\n",
    "            top_lookalikes.append((customer_profile.iloc[i[0]]['CustomerID'], score))\n",
    "            count += 1\n",
    "    \n",
    "    # Store the result in the dictionary\n",
    "    lookalikes[customer_id] = top_lookalikes\n",
    "\n",
    "# Step 4: Convert the lookalikes dictionary to a DataFrame with a Map structure\n",
    "lookalike_df = pd.DataFrame(\n",
    "    [(cust_id, str(lookalikes[cust_id])) for cust_id in lookalikes], \n",
    "    columns=['CustomerID', 'Lookalikes']\n",
    ")\n",
    "\n",
    "# Step 5: Save the result to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
    "\n",
    "# Display the first few entries (top 3 lookalikes for the first 20 customers)\n",
    "print(lookalike_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e57210-3f7b-4268-9c9b-beb2d37a6ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
